# Lexer Documentation

## Overview

The **Lexer** (lexical analyzer/tokenizer) is the first stage of the Bhasa language interpreter. It converts raw source code text into a stream of **tokens** that can be parsed by the parser.

## Table of Contents

- [What is a Lexer?](#what-is-a-lexer)
- [Key Features](#key-features)
- [Architecture](#architecture)
- [Token Types](#token-types)
- [Usage](#usage)
- [Unicode Support](#unicode-support)
- [Position Tracking](#position-tracking)
- [For More Details](#for-more-details)

## What is a Lexer?

A **lexer** (also called a **scanner** or **tokenizer**) performs **lexical analysis** - the process of converting a sequence of characters into a sequence of tokens. It's the first phase of compilation/interpretation.

### Example

**Input (Source Code):**
```bengali
‡¶ß‡¶∞‡¶ø x = ‡ß´;
```

**Output (Token Stream):**
```
Token{Type: LET, Literal: "‡¶ß‡¶∞‡¶ø", Line: 1, Column: 1}
Token{Type: IDENT, Literal: "x", Line: 1, Column: 5}
Token{Type: ASSIGN, Literal: "=", Line: 1, Column: 7}
Token{Type: INT, Literal: "5", Line: 1, Column: 9}
Token{Type: SEMICOLON, Literal: ";", Line: 1, Column: 10}
Token{Type: EOF, Literal: "", Line: 1, Column: 11}
```

## Key Features

### 1. **Unicode Support** üåê
- Full support for Bengali script (UTF-8)
- Uses `rune` type (int32) instead of `byte` to handle multi-byte characters
- Supports Bengali vowel signs (‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ) and diacritics

### 2. **Bengali & Arabic Numerals** üî¢
- Accepts both Arabic (0-9) and Bengali (‡ß¶-‡ßØ) digits
- Automatically converts Bengali digits to Arabic internally
- Examples: `‡ßß‡ß®‡ß©` ‚Üí `123`, `‡ß´‡ß¶` ‚Üí `50`

### 3. **Position Tracking** üìç
- Tracks line and column numbers for every token
- Essential for error reporting with accurate locations
- Automatically handles newlines and column counting

### 4. **Peek-Ahead** üëÄ
- Can look at the next character without consuming it
- Necessary for multi-character operators like `==`, `<=`, `>>`
- Enables single-pass tokenization

### 5. **Comment Support** üí¨
- Line comments start with `//`
- Comments are automatically skipped during tokenization
- Whitespace and comments are ignored

### 6. **Comprehensive Operators** ‚öôÔ∏è
- Arithmetic: `+`, `-`, `*`, `/`, `%`
- Comparison: `==`, `!=`, `<`, `>`, `<=`, `>=`
- Logical: `&&`, `||`, `!`
- Bitwise: `&`, `|`, `^`, `~`, `<<`, `>>`
- Assignment: `=`
- Function arrow: `=>`

## Architecture

### Lexer Structure

```go
type Lexer struct {
    input        []rune  // Input as rune slice (Unicode support)
    position     int     // Current position (current char)
    readPosition int     // Next reading position (next char)
    ch           rune    // Current character under examination
    line         int     // Current line number (starts at 1)
    column       int     // Current column number (starts at 0)
}
```

### State Machine

The lexer operates as a **state machine** with the following states:

1. **Start**: Begin processing from position 0
2. **Read Character**: Consume next character
3. **Classify**: Determine token type based on character
4. **Multi-char Check**: Use peek-ahead for operators like `==`, `&&`
5. **Build Token**: Create token with type, literal, position
6. **Repeat**: Continue until EOF

### Single-Pass Design

The lexer processes input in a **single pass** from left to right:
- No backtracking required
- Efficient memory usage
- O(n) time complexity where n = input length

## Token Types

The lexer recognizes several categories of tokens:

### 1. **Keywords** (Bengali)
```
‡¶ß‡¶∞‡¶ø        (let)          - Variable declaration
‡¶´‡¶æ‡¶Ç‡¶∂‡¶®      (function)     - Function definition
‡¶Ø‡¶¶‡¶ø        (if)           - Conditional
‡¶®‡¶æ‡¶π‡¶≤‡ßá      (else)         - Else clause
‡¶´‡ßá‡¶∞‡¶§       (return)       - Return statement
‡¶∏‡¶§‡ßç‡¶Ø       (true)         - Boolean true
‡¶Æ‡¶ø‡¶•‡ßç‡¶Ø‡¶æ     (false)        - Boolean false
‡¶Ø‡¶§‡¶ï‡ßç‡¶∑‡¶£     (while)        - While loop
```

### 2. **Identifiers**
- Variable names and function names
- Must start with letter or underscore
- Can contain letters, digits, underscores
- Supports Bengali characters and vowel signs

### 3. **Literals**
- **Integers**: `123`, `‡ß™‡ß´‡ß¨` (both Arabic and Bengali)
- **Strings**: `"‡¶π‡ßç‡¶Ø‡¶æ‡¶≤‡ßã"`, `"Hello"`

### 4. **Operators**
- Arithmetic, comparison, logical, bitwise (see Key Features)

### 5. **Delimiters**
- `(` `)` `{` `}` `[` `]` - Grouping
- `,` `;` `:` `.` - Separators

### 6. **Special**
- `EOF` - End of file
- `ILLEGAL` - Unrecognized character

## Usage

### Basic Usage

```go
import (
    "bhasa/lexer"
    "bhasa/token"
)

// Create a new lexer
input := `‡¶ß‡¶∞‡¶ø x = ‡ßß‡ß¶;`
l := lexer.New(input)

// Get tokens one by one
for {
    tok := l.NextToken()
    
    fmt.Printf("Type: %s, Literal: %s, Line: %d, Col: %d\n",
        tok.Type, tok.Literal, tok.Line, tok.Column)
    
    if tok.Type == token.EOF {
        break
    }
}
```

### Tokenizing a Complete Program

```go
input := `
‡¶ß‡¶∞‡¶ø ‡¶´‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶ü‡ßã‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤ = ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®(n) {
    ‡¶Ø‡¶¶‡¶ø (n <= ‡ßß) {
        ‡¶´‡ßá‡¶∞‡¶§ ‡ßß;
    }
    ‡¶´‡ßá‡¶∞‡¶§ n * ‡¶´‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶ü‡ßã‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤(n - ‡ßß);
};
`

l := lexer.New(input)
tokens := []token.Token{}

for {
    tok := l.NextToken()
    tokens = append(tokens, tok)
    if tok.Type == token.EOF {
        break
    }
}
```

## Unicode Support

### Why Runes?

Go's `string` type is a sequence of bytes, but Unicode characters can be multiple bytes. Bengali characters often use 2-3 bytes per character.

**Solution**: Use `[]rune` instead of `string`:
- `rune` is an alias for `int32`
- Represents a single Unicode code point
- Bengali character "‡¶ï" = single rune (multiple bytes)

### Bengali Script Features

#### 1. **Vowel Signs (‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ)**
```
‡¶ï  ‚Üí single character
‡¶ï‡¶æ ‚Üí ‡¶ï + ‡¶æ (base + vowel sign)
‡¶ï‡¶ø ‚Üí ‡¶ï + ‡¶ø (base + vowel sign)
```

The lexer recognizes vowel signs (U+0981 to U+09CD) as part of identifiers.

#### 2. **Combining Marks**
```
‡¶ï‡¶Ç ‚Üí ‡¶ï + ‡¶Ç (anusvara)
‡¶ï‡¶É ‚Üí ‡¶ï + ‡¶É (visarga)
```

These are handled using `unicode.Mn` (nonspacing marks) category.

#### 3. **Conjuncts (‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶æ‡¶ï‡ßç‡¶∑‡¶∞)**
```
‡¶ï‡ßç‡¶∑ ‚Üí ‡¶ï + ‡ßç + ‡¶∑
‡¶∏‡ßç‡¶§ ‚Üí ‡¶∏ + ‡ßç + ‡¶§
```

The hasant (‡ßç) and following consonant form conjuncts.

### Bengali Digit Conversion

```go
// Input: "‡ßß‡ß®‡ß©"
// Lexer sees: rune '‡ßß', rune '‡ß®', rune '‡ß©'
// Reads as: "‡ßß‡ß®‡ß©"
// Converts to: "123"
// Returns: Token{Type: INT, Literal: "123"}
```

**Conversion Table:**
```
‡ß¶ ‚Üí 0    ‡ß´ ‚Üí 5
‡ßß ‚Üí 1    ‡ß¨ ‚Üí 6
‡ß® ‚Üí 2    ‡ß≠ ‚Üí 7
‡ß© ‚Üí 3    ‡ßÆ ‚Üí 8
‡ß™ ‚Üí 4    ‡ßØ ‚Üí 9
```

## Position Tracking

### Line and Column Tracking

The lexer maintains accurate position information:

```
Line 1: ‡¶ß‡¶∞‡¶ø x = ‡ß´;
        ^   ^   ^  ^
        1   5   9  11 (columns)

Line 2: ‡¶ß‡¶∞‡¶ø y = ‡ßß‡ß¶;
        ^   ^   ^   ^
        1   5   9   12 (columns)
```

### Newline Handling

When `\n` is encountered:
1. Increment `line` counter
2. Reset `column` to 0
3. Continue reading

### Token Position

Each token records its starting position:

```go
tok := token.Token{
    Type:    token.LET,
    Literal: "‡¶ß‡¶∞‡¶ø",
    Line:    1,      // Starting line
    Column:  1,      // Starting column
}
```

### Use in Error Reporting

Position information enables helpful error messages:

```
Error at line 5, column 12: unexpected token '!'
    ‡¶ß‡¶∞‡¶ø x = ‡ßß‡ß¶!
               ^
```

## For More Details

For comprehensive documentation with implementation details, examples, and advanced topics, see:

- **[Lexer Implementation Guide](./lexer-documentation.md)** - Complete technical reference

## Quick Reference

### Core Functions

| Function | Purpose |
|----------|---------|
| `New(input string)` | Create new lexer |
| `NextToken()` | Get next token |
| `readChar()` | Consume next character |
| `peekChar()` | Look ahead without consuming |
| `readIdentifier()` | Read variable/keyword name |
| `readNumber()` | Read integer literal |
| `readString()` | Read string literal |
| `skipWhitespace()` | Skip spaces, tabs, newlines |
| `skipComment()` | Skip line comments |

### Helper Functions

| Function | Purpose |
|----------|---------|
| `isLetter(ch)` | Check if character is letter |
| `isDigit(ch)` | Check if character is Arabic digit |
| `isBengaliDigit(ch)` | Check if character is Bengali digit |
| `isBengaliVowelSign(ch)` | Check if character is vowel sign |

## Example: Complete Tokenization

**Input:**
```bengali
// ‡¶´‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶ü‡ßã‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤ ‡¶ó‡¶£‡¶®‡¶æ
‡¶ß‡¶∞‡¶ø ‡¶´‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶ü‡ßã‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤ = ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®(n) {
    ‡¶Ø‡¶¶‡¶ø (n <= ‡ßß) {
        ‡¶´‡ßá‡¶∞‡¶§ ‡ßß;
    }
    ‡¶´‡ßá‡¶∞‡¶§ n * ‡¶´‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶ü‡ßã‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤(n - ‡ßß);
};
```

**Token Stream:**
```
// Comment skipped
LET      "‡¶ß‡¶∞‡¶ø"              line 2, col 1
IDENT    "‡¶´‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶ü‡ßã‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤"    line 2, col 5
ASSIGN   "="                line 2, col 18
FUNCTION "‡¶´‡¶æ‡¶Ç‡¶∂‡¶®"            line 2, col 20
LPAREN   "("                line 2, col 26
IDENT    "n"                line 2, col 27
RPAREN   ")"                line 2, col 28
LBRACE   "{"                line 2, col 30
IF       "‡¶Ø‡¶¶‡¶ø"              line 3, col 5
LPAREN   "("                line 3, col 9
IDENT    "n"                line 3, col 10
LTE      "<="               line 3, col 12
INT      "1"                line 3, col 15
RPAREN   ")"                line 3, col 16
LBRACE   "{"                line 3, col 18
RETURN   "‡¶´‡ßá‡¶∞‡¶§"             line 4, col 9
INT      "1"                line 4, col 14
SEMICOLON ";"               line 4, col 15
RBRACE   "}"                line 5, col 5
RETURN   "‡¶´‡ßá‡¶∞‡¶§"             line 6, col 5
IDENT    "n"                line 6, col 10
ASTERISK "*"                line 6, col 12
IDENT    "‡¶´‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶ü‡ßã‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤"    line 6, col 14
LPAREN   "("                line 6, col 27
IDENT    "n"                line 6, col 28
MINUS    "-"                line 6, col 30
INT      "1"                line 6, col 32
RPAREN   ")"                line 6, col 33
SEMICOLON ";"               line 6, col 34
RBRACE   "}"                line 7, col 1
SEMICOLON ";"               line 7, col 2
EOF      ""                 line 7, col 3
```

## Benefits of Lexer Design

### 1. **Separation of Concerns**
- Lexer: Character ‚Üí Token
- Parser: Token ‚Üí AST
- Clear boundaries and responsibilities

### 2. **Error Detection**
- Invalid characters detected immediately
- Position tracking for error messages
- Fail fast on illegal input

### 3. **Flexibility**
- Easy to add new operators
- Easy to add new keywords
- Minimal changes to parser

### 4. **Performance**
- Single-pass algorithm
- No backtracking
- Efficient memory usage

### 5. **Maintainability**
- Clear, readable code
- Easy to test individual functions
- Well-defined token types

---

## Summary

The **Bhasa Lexer** is a robust, Unicode-aware tokenizer that:
- ‚úÖ Handles Bengali script and vowel signs
- ‚úÖ Supports both Arabic and Bengali numerals
- ‚úÖ Tracks positions for error reporting
- ‚úÖ Recognizes 30+ Bengali keywords
- ‚úÖ Supports comprehensive operator set
- ‚úÖ Implements efficient single-pass algorithm
- ‚úÖ Provides clean interface for parser

For implementation details, see [lexer-documentation.md](./lexer-documentation.md).

